{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This runs a forecast pipeline using both python and R\n",
    "\n",
    "It uses a hypbrid approach with two R forecasters that worked well in the past as described in\n",
    "https://robjhyndman.com/hyndsight/show-me-the-evidence/. It combines ETS and auto.ARIMA outputs equally weighted.\n",
    "\n",
    "\n",
    "1. Important R packages required in conda include: r-essentials, r-forecast, r-tseries, rpy2\n",
    "   I had to install the R package Mcomp in R using the command: install.packages(\"Mcomp\") which interacts with a user\n",
    "   to select a mirror site.\n",
    "   \n",
    "2. This works in a conda environment with python 3.6.3, numpy, pandas, and other normal packages on windows 10 64 bits\n",
    "   with Anaconda 3 5.01 64 bit \n",
    "   \n",
    "3. It needs no special arguments but will find the data and run a prediction based on the dataset file structure assuming \n",
    "   that the data, problem, and solution directories are at the same level below the dataset root directory.\n",
    "   \n",
    "4. This pipeline also assumes a forecasting problem with the data to forecast at the end of the provided data as\n",
    "   specified in the splits file.\n",
    "\n",
    "'''\n",
    "\n",
    "# need this to run both python and R\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tseries', 'forecast', 'tools', 'stats', 'graphics', 'grDevices',\n",
       "       'utils', 'datasets', 'methods', 'base'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these R libraries are necessary for advanced time series forecasting\n",
    "%R library(forecast)\n",
    "%R library(tseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory: C:\\Users\\cllippmann\\d3m\\datasets\\LL1_fluid_milk_wholesale_price_all_industry\\LL1_fluid_milk_wholesale_price_all_industry_dataset\n",
      "problem directory C:\\Users\\cllippmann\\d3m\\datasets\\LL1_fluid_milk_wholesale_price_all_industry\\LL1_fluid_milk_wholesale_price_all_industry_problem\n",
      "solution directory C:\\Users\\cllippmann\\d3m\\datasets\\LL1_fluid_milk_wholesale_price_all_industry\\LL1_fluid_milk_wholesale_price_all_industry_solution\n"
     ]
    }
   ],
   "source": [
    "# find paths to data schema, problem schema, data, and splits file\n",
    "import os, ntpath\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# get names of the three main dataset directories\n",
    "path = os.getcwd()\n",
    "solution_dir_name = ntpath.basename(path)\n",
    "data_dir_name = solution_dir_name.replace(\"solution\", \"dataset\")\n",
    "problem_dir_name = solution_dir_name.replace(\"solution\", \"problem\")\n",
    "\n",
    "solution_dir_path = os.getcwd()\n",
    "ds = \"../\" + data_dir_name\n",
    "data_dir_path = Path(ds).resolve()\n",
    "ps = \"../\" + problem_dir_name\n",
    "problem_dir_path = Path(ps).resolve()\n",
    "\n",
    "\n",
    "print(\"data directory: %s\\nproblem directory %s\\nsolution directory %s\" % (data_dir_path, problem_dir_path, solution_dir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cllippmann\\d3m\\datasets\\LL1_fluid_milk_wholesale_price_all_industry\\LL1_fluid_milk_wholesale_price_all_industry_dataset\\tables\\learningData.csv\n",
      "C:\\Users\\cllippmann\\d3m\\datasets\\LL1_fluid_milk_wholesale_price_all_industry\\LL1_fluid_milk_wholesale_price_all_industry_problem\\dataSplits.csv\n"
     ]
    }
   ],
   "source": [
    "#%pylab\n",
    "# read in all data assuming this is time series data where the training data comes first and the test data follows\n",
    "learning_data_path = Path(str(data_dir_path) + \"/tables/learningData.csv\").resolve()\n",
    "print(learning_data_path)\n",
    "df_data = pd.read_csv(learning_data_path, index_col='d3mIndex')\n",
    "all_data = np.asarray(df_data[\"value\"])\n",
    "\n",
    "# get train/test splits\n",
    "splits_data_path = Path(str(problem_dir_path) + \"/dataSplits.csv\").resolve()\n",
    "print(splits_data_path)\n",
    "\n",
    "df_splits = pd.read_csv(splits_data_path, index_col='d3mIndex')\n",
    "train_flags = df_splits[df_splits['type']=='TRAIN']\n",
    "test_flags = df_splits[df_splits['type']=='TEST']\n",
    "xlen = len(train_flags)\n",
    "xxlen = len(test_flags)\n",
    "\n",
    "x = np.zeros(xlen)\n",
    "xx = np.zeros(xxlen)\n",
    "x=all_data[0:xlen]\n",
    "xx = all_data[xlen:]\n",
    "hh = len(xx)\n",
    "#plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i x,hh -o p1,p2 -o y\n",
    "p1 = forecast(auto.arima(x),h=hh)$mean\n",
    "p2 = forecast(ets(x), h=hh)$mean\n",
    "y = 0.5*(p1+p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series:\n",
      "\r\n",
      "Start = 116 \n",
      "\r\n",
      "End = 133 \n",
      "\r\n",
      "Frequency = 1 \n",
      "\r\n",
      " [1] 2678.470 2657.861 2637.896 2618.626 2603.679 2594.028 2589.087 2587.582\n",
      "\r\n",
      " [9] 2588.154 2589.677 2591.374 2592.812 2593.821 2594.402 2594.643 2594.660\n",
      "\r\n",
      "[17] 2594.559 2594.417\n",
      " Time Series:\n",
      "\r\n",
      "Start = 116 \n",
      "\r\n",
      "End = 133 \n",
      "\r\n",
      "Frequency = 1 \n",
      "\r\n",
      " [1] 2712.064 2737.681 2758.174 2774.569 2787.684 2798.177 2806.571 2813.286\n",
      "\r\n",
      " [9] 2818.658 2822.956 2826.394 2829.145 2831.345 2833.106 2834.514 2835.641\n",
      "\r\n",
      "[17] 2836.542 2837.263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i x,p1,p2,xlen,xxlen\n",
    "jpeg('forecast-plot.png')\n",
    "plot(x,xlim=c(0,xlen+xxlen))\n",
    "lines(x)\n",
    "lines(p1,col='red')\n",
    "lines(p2,col='blue')\n",
    "lines(y,col='green')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on test data (rmse): 138.943969746\n",
      "saving the performance score ...\n"
     ]
    }
   ],
   "source": [
    "# compute error on test data\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_truth = xx\n",
    "y_predicted = np.array(y)\n",
    "rmse = np.sqrt(mean_squared_error(y_truth, y_predicted))\n",
    "print('performance on test data (rmse):',rmse)\n",
    "print('saving the performance score ...')\n",
    "test_performance = OrderedDict([\n",
    "    ('test', OrderedDict([\n",
    "        ('score', OrderedDict([\n",
    "                ('metric', 'rootMeanSquaredError'),\n",
    "                ('value', rmse)])\n",
    "        )\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"test\": {\n",
      "    \"score\": {\n",
      "      \"metric\": \"rootMeanSquaredError\",\n",
      "      \"value\": 138.943969746418\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# create scores file\n",
    "overall_performance = OrderedDict()\n",
    "overall_performance.update(test_performance)\n",
    "\n",
    "with open('scores.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(overall_performance, f, indent=2)\n",
    "print(json.dumps(overall_performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create predictions file\n",
    "test_flags\n",
    "preds= pd.Series(xx)\n",
    "test_flags = test_flags.assign(a=preds.values)\n",
    "test_flags.rename(columns={'a': '0'}, inplace=True)\n",
    "test_flags.to_csv(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

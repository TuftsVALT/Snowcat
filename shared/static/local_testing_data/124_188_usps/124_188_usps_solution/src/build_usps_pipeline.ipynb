{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as skimg_io\n",
    "from sklearn.metrics import accuracy_score\n",
    "from d3mds import D3MDS\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imgs_from_files(img_files, img_dir):\n",
    "    X = []\n",
    "    for i, img_file in enumerate(img_files):\n",
    "        if i % 1000 == 0:\n",
    "            print('Loading Image %d' % i)\n",
    "        img = skimg_io.imread(os.path.join(img_dir, img_file))        \n",
    "        X.append(img)\n",
    "    X = np.stack(X, axis=0)\n",
    "    X = X[:, :, :, None]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes=10, input_size=16):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                     activation='relu',\n",
    "                     input_shape=(input_size, input_size, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes))#, activation='softmax'))\n",
    "    model.add(Activation(tf.nn.softmax))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, X_test, y_test):\n",
    "    preds = np.argmax(model.predict(X_test), axis=1)\n",
    "    preds += 1\n",
    "    acc_test = accuracy_score(y_test, preds)\n",
    "    print('Test Accuracy: %.2f' % (acc_test * 100))\n",
    "    return acc_test, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions_csv_file(inds, preds, prediction_filename):     \n",
    "    df = pd.DataFrame(preds, index=inds, columns=['label'])\n",
    "    df.to_csv(prediction_filename, index_label='d3mIndex')\n",
    "\n",
    "def write_scores_csv_file(metric_dict, score_filename):    \n",
    "    metric_names = []\n",
    "    metric_values = []\n",
    "    for metric_name, metric_value in metric_dict.items():\n",
    "        metric_names.append(metric_name)\n",
    "        metric_values.append(metric_value)\n",
    "    metric_names = np.array(metric_names)\n",
    "    metric_values = np.array(metric_values)\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((metric_names[:, None], metric_values[:, None]), axis=1), columns=['metric', 'value'])\n",
    "    df.to_csv(score_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DATA\n"
     ]
    }
   ],
   "source": [
    "dataset_root = '../../'\n",
    "model_dir = './models/'\n",
    "\n",
    "print('Load DATA')    \n",
    "data_path = glob.glob(os.path.join(dataset_root, \"*_dataset\"))[0]\n",
    "problem_path = glob.glob(os.path.join(dataset_root, \"*_problem\"))[0]\n",
    "d3mds = D3MDS(data_path, problem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load train data\n",
      "Loading Image 0\n",
      "Loading Image 1000\n",
      "Loading Image 2000\n",
      "Loading Image 3000\n",
      "Loading Image 4000\n",
      "Loading Image 5000\n",
      "Loading Image 6000\n",
      "Loading Image 7000\n",
      "(7291, 16, 16, 1) (7291, 1)\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoad train data')\n",
    "df_train = d3mds.get_train_data()\n",
    "media_dir = os.path.join(data_path, 'media')\n",
    "X_train = load_imgs_from_files(df_train['image'], media_dir)\n",
    "y_train = d3mds.get_train_targets()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test data\n",
      "Loading Image 0\n",
      "Loading Image 1000\n",
      "Loading Image 2000\n",
      "(2007, 16, 16, 1) (2007, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Load test data')\n",
    "df_test = d3mds.get_test_data()\n",
    "X_test = load_imgs_from_files(df_test['image'], media_dir)\n",
    "y_test = d3mds.get_test_targets()\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 72,738\n",
      "Trainable params: 72,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "model = build_model(num_classes=num_classes, input_size=X_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 1/10\n",
      "7291/7291 [==============================] - 1s 180us/step - loss: 2.2521 - acc: 0.2301\n",
      "Epoch 2/10\n",
      "7291/7291 [==============================] - 1s 129us/step - loss: 2.1654 - acc: 0.3004\n",
      "Epoch 3/10\n",
      "7291/7291 [==============================] - 1s 135us/step - loss: 2.0174 - acc: 0.3322\n",
      "Epoch 4/10\n",
      "7291/7291 [==============================] - 1s 130us/step - loss: 1.7440 - acc: 0.4578\n",
      "Epoch 5/10\n",
      "7291/7291 [==============================] - 1s 134us/step - loss: 1.3662 - acc: 0.6762\n",
      "Epoch 6/10\n",
      "7291/7291 [==============================] - 1s 126us/step - loss: 1.0107 - acc: 0.7895\n",
      "Epoch 7/10\n",
      "7291/7291 [==============================] - 1s 131us/step - loss: 0.7632 - acc: 0.8299\n",
      "Epoch 8/10\n",
      "7291/7291 [==============================] - 1s 134us/step - loss: 0.6136 - acc: 0.8494\n",
      "Epoch 9/10\n",
      "7291/7291 [==============================] - 1s 131us/step - loss: 0.5266 - acc: 0.8611\n",
      "Epoch 10/10\n",
      "7291/7291 [==============================] - 1s 137us/step - loss: 0.4728 - acc: 0.8701\n",
      "Performance on TEST sest\n",
      "Test Accuracy: 83.46\n"
     ]
    }
   ],
   "source": [
    "y_train_temp = y_train - 1\n",
    "y_train_one_hot = to_categorical(y_train_temp, num_classes=num_classes)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_file = 'model_weights.h5'\n",
    "model_full_path = os.path.join(model_dir, model_file)\n",
    "if os.path.exists(model_full_path):\n",
    "    print('Loading model from %s' % model_full_path)\n",
    "    model.load_weights(model_full_path)\n",
    "else:\n",
    "    print('Training model')\n",
    "    model.fit(X_train, y_train_one_hot,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1)\n",
    "    model.save(model_full_path)\n",
    "\n",
    "print('Performance on TEST sest')\n",
    "acc_test, preds_test = evaluate_on_test_set(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions to .csv file.\n",
      "Writing scores to .csv file.\n"
     ]
    }
   ],
   "source": [
    "print('Writing predictions to .csv file.')\n",
    "cur_dir = './'\n",
    "predictions_file = os.path.join(cur_dir, 'predictions.csv')\n",
    "write_predictions_csv_file(df_test.index, preds_test, predictions_file)\n",
    "\n",
    "print('Writing scores to .csv file.')\n",
    "metric_dict = {'accuracy': acc_test}\n",
    "scores_file = os.path.join(cur_dir, 'scores.csv')\n",
    "write_scores_csv_file(metric_dict, scores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
